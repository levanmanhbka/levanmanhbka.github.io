---
title: Airflow
date: 2023-12-07 22:34:00 +0800
categories: [MLOPs, Ochestration Tool]
tags: [mlops]     # TAG names should always be lowercase
---

---
## Worflow Define
Worflow là một tập hợp nhiều Task được sắp xếp theo một thứ tự nhất định, phụ thuộc vào từng bài toán cụ thể. Ví dụ work flow trong việc huấn luyện mô hình Machine Learning sẽ như sau: Data Extraction -> Data Validation -> Data Preparation -> Model Training -> Model Evaludation -> Model Validation.

Các workfow sẽ được mô tả, lập lịch hoặc khởi động chạy, theo dõi quá trình thực hiện các Task trong đó bằng một công cụ gọi là Orchestration Tool


## Orchestration Tools
Airflow là một pipeline orchestration tool trong MLOPs, ngoài ra còn có một số tool khác như cron, luigi, airflow, kubeflow, kedro, metaflow, dagster, flyte, prefect, zenml

![Orchestration Tools](/assets/2023-12-07-airflow/orchestration-tools.png){: width="1000" height="400" }
_Cron, Luigi, Airflow, Kubeflow, Kedro, Metaflow, Dagster, Flyte, Prefect, and Zenml (left to right; top to bottom)_


## Airflow Architecture
![Airflow Arichitecture](/assets/2023-12-07-airflow/arch-diag-basic.png){: width="1000" height="400" }
_Airflow Airchitecture_

- DAG Directory: Nơi chứa các file.py định nghĩa các workflow
- Scheduler: Khởi động các worfkow và chuyển các workflow cho Executor thực hiện
- Executor: Thực hiện các Task được mô tả trong workflow
- Worker: Executor có thể thực hiện các Task ngay trong process của Sheduler hoặc gửi các Task cho Worker thực hiện ở một process khác.
- Metada Database: Nơi lưu toàn bộ trạng thái và các thông tin metada của các workflow và các Task
- Webserver: Cung cấp User Interface hiển thị các thông tin về workflow và các Task cũng như có thể khởi động một workflow từ GUI Interface

Sau đây chúng ta sẽ đi chi tiết vào từng thành phần của Airflow


## Workflow
A workflow được thể hiện dưới dạng một đồ thị không vòng DAG (Directed Acyclic Graph). Trong đó mỗi Node chính là một Task ví dụ:
![Airflow Arichitecture](/assets/2023-12-07-airflow/dag_example.png){: width="1000" height="400" }
_DAG Example_

DAG được định nghĩa bằng một file python, có nhiều cách định nghĩa DAG và Task bên trong nó, tuy nhiên mình thấy sử dụng decorator @dag và @task tường minh nhất. Sau đây là ví dụ một DAG
```python:
@dag(start_date=now, schedule="@daily", catchup=False)
def etl():
    @task()
    def retrieve(src: Dataset) -> dict:
        resp = requests.get(url=src.uri)
        data = resp.json()
        return data["data"]

    @task()
    def to_fahrenheit(temps: dict[int, float]) -> dict[int, float]:
        ret: dict[int, float] = {}
        for year, celsius in temps.items():
            ret[year] = float(celsius) * 1.8 + 32

        return ret

    @task()
    def load(fahrenheit: dict[int, float]) -> Dataset:
        filename = "/tmp/fahrenheit.json"
        s = json.dumps(fahrenheit)
        f = open(filename, "w")
        f.write(s)
        f.close()

        return Dataset(f"file:///{filename}")

    data = retrieve(SRC)
    fahrenheit = to_fahrenheit(data)
    load(fahrenheit)


etl()
```
---

## Task
Task là thành phần thực hiện công việc cơ bản trong Workflow. Có ba loại Task:
- Operators: là loại task được định nghĩa trước giống như thư viện chuẩn chỉ việc gọi là xong, có hai loại Operator là Build In Operator có sẵn trong Airflow, còn một loại là Provider Operator cần cài thêm thông qua providers packages

| Build In Operator | Responsibility |
| :---------------- | :------|
| BashOperator | executes a bash command   |
| BashOperator | executes a bash command|
| PythonOperator| calls an arbitrary Python function|
| EmailOperator | sends an email|

| Provider Operator | Responsibility |
| :---------------- | :------|
| SimpleHttpOperator |
| MySqlOperator |
| PostgresOperator |
| MsSqlOperator |
| OracleOperator |
| JdbcOperator |
| DockerOperator |
| HiveOperator |
| S3FileTransformOperator |
| PrestoToMySqlOperator |
| SlackAPIOperator |



- Sensors: là một trường hợp đặc biệt của Operator, nó làm một nhiệm vụ duy nhất là lắng nghe event sảy ra. Ví dụ: FileSensor, DateTimeSensor, ExternalTaskSensor, PythonSensor

- TaskFlow: chính là việc người dùng tự định nghĩa một hàm Python và biến nó thành Task nhờ decorator @task

Các Task trong quá trình thực thi bở Executor có thể trao đổi thông tin qua lại cho nhau thông qua Xcom

## Xcom
Kiến trúc hoạt động của Xcom được mô tả trong hình sau đây:
![Xcom Airchitecture](/assets/2023-12-07-airflow/xcom.png){:width="1000" height="400"}
_Xcom Architecture_

Sau đây là code ví dụ sử dụng Xcom:
```python
value_1 = [1, 2, 3]
@task
def push(ti=None):
    """Pushes an XCom without a specific target"""
    ti.xcom_push(key="value from pusher 1", value=value_1)

@task
def puller(pulled_value_2, ti=None):
    """Pull all previously pushed XComs"""
    pulled_value_1 = ti.xcom_pull(task_ids="push", key="value from pusher 1")
```
Trong đó "ti" là một macro được airflow định nghĩa trước, ngoài ra còn nhiều macro khác có thể tham khảo ở đây: https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html

## Executor
Như đã nhắc đến ở phần trước, Executor chịu trách nhiện thực hiện các Task, sau đây là một số loại Executor:

Local Executors
| Name | Feature|
| :--- | :---|
Local Executor | Thực hiện task song song trong process của Scheduler
Sequential Executor | Thực hiện task tuần tự trong process của Scheduler

Remote Executors
| Name | Feature|
| :--- | :---|
Celery Executor | Mode phổ biến để thực hiên distribution system
CeleryKubernetes Executor
Dask Executor 
Kubernetes Executor | Mode nâng cao để thực hiện distribution system

## Sequential Executor
![Sequential Executor](/assets/2023-12-07-airflow/sequencial-executor.png){:width="1000" height="400"}
_Sequential Executor Airchitecture (https://maxcotec.com/learning/apache-airflow-architecture/)_
Pros

- No Setup Required: comes as default executor preconfigured with airflow
- Light Weight: no extra nodes required, all tasks run on scheduler node
- Cheap: due to its light weight

Cons
- Slow: runs one task at a time
- Not Scalable: because tasks run on same node where scheduler is running
- Single point of failure: Tasks fail if scheduler node dies
- Not Suitable for production: Because of all above


## Local Executor
![Local Executor](/assets/2023-12-07-airflow/local-executor.png){:width="1000" height="400"}
_Local Executor Airchitecture (https://maxcotec.com/learning/apache-airflow-architecture/)_

Pros:
- Easy to Setup: simply set environment variable AIRFLOW__CORE__EXECUTOR=LocalExecutor
- Cheap & Light Weight: Task instances run on same machine where scheduler is running, so no extra resources required
- Fast: Can run multiple tasks at a time

Cons:
- Single point of failure: Tasks fail if scheduler node dies
- Not suitable to scale: limited to scheduler node resources
- Not suitable for production: because of all above


## Celary Executor
![Local Executor](/assets/2023-12-07-airflow/celery-executor.png){:width="1000" height="400"}
_Celary Executor Airchitecture (https://maxcotec.com/learning/apache-airflow-architecture/)_

Pros:
- Horizontally scalable: Set as many number of workers as required
- Fault tolerant: If a worker goes down, celery executor automatically assigns a task(s) to another healthy worker
- Production ready: due to all above

Cons:
- Relatively Complex setup: Additional resource setup required RabbbitMQ broker and workers
- Resource wastage if no task scheduled: Celery workers always running even if the task queue is empty
- Not cost effective: its pricier because of additional resources plus due to resource wastage.


## Cubernetes Executor
![Local Executor](/assets/2023-12-07-airflow/celery-executor.png){:width="1000" height="400"}
_Cubernetes Executor Airchitecture (https://maxcotec.com/learning/apache-airflow-architecture/)_

Pros:
- Can Scale down to zero:  If no task(s) is scheduled, no worker pod will spin-up, whereas it can scale up to as many pods as required. So no resource wastage.
- Fault tolerant: Pods are re-spawned upon non-success termination
- Flexible resource allocation: Each task can individually be assigned its memory allocation, airflow image as well as service account.
- Cost & resource effective: Won’t be charged extra if no tasks(s) is scheduled

Cons:
- Pod launch time: A new worker pod spins-up upon new tasks execution. This adds few seconds of latency in workflow.
- Complex setup: Requires kubernetes knowledge, setting up cluster and executor configurations on top

## Install
Trong trường hợp sử dụng môi trường Linux, dùng docker compose để chạy, chi tiết tham khảo ở link sau:
https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html